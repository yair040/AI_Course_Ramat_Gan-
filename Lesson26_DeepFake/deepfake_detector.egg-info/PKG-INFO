Metadata-Version: 2.4
Name: deepfake-detector
Version: 1.0.0
Summary: A comprehensive tool for detecting deepfake manipulations in video files
Author: Yair Levi
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Multimedia :: Video
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: opencv-python>=4.8.0
Requires-Dist: opencv-contrib-python>=4.8.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: scipy>=1.11.0
Requires-Dist: torch>=2.1.0
Requires-Dist: face-recognition>=1.3.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: pandas>=2.1.0
Provides-Extra: full
Requires-Dist: pymediainfo>=6.1.0; extra == "full"
Requires-Dist: tensorflow>=2.15.0; extra == "full"
Requires-Dist: mediapipe>=0.10.0; extra == "full"
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: pytest-cov>=4.1.0; extra == "dev"
Requires-Dist: pylint>=3.0.0; extra == "dev"
Requires-Dist: black>=23.12.0; extra == "dev"
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# DeepFake Video Detection Tool

**Author:** Yair Levi  
**Version:** 1.0.0  
**Platform:** WSL (Windows Subsystem for Linux)  
**Python:** 3.9+

A comprehensive Python tool for detecting deepfake manipulations in video files through multi-criteria analysis including facial inconsistencies, temporal anomalies, lighting analysis, geometry validation, and machine learning detection.

## Features

### Detection Capabilities

✅ **Facial Expression Analysis**
- Micro-expression consistency (smile lines, frown creases)
- Eye shape symmetry and teeth alignment
- Jaw angle naturalness
- Face boundary artifact detection

✅ **Temporal Consistency**
- Motion tracking and velocity analysis
- Unnatural jitter detection
- Frame-to-frame smoothness evaluation
- Posture and lighting change detection

✅ **Metadata Inspection**
- Container and codec analysis
- Timestamp consistency verification
- Re-encoding signature detection
- Compression artifact identification

✅ **Lighting & Shadow Analysis**
- Direction and color temperature consistency
- Specular highlight validation
- Shadow geometry verification
- Reflection consistency (eyes, glasses, surfaces)

✅ **Eye & Pupil Analysis**
- Blink frequency and duration
- Pupil dilation response to lighting
- Saccade movement naturalness
- Eye reflection validation

✅ **Geometry & Physiology**
- Facial feature spacing consistency
- 3D parallax validation
- Head rotation tracking
- Micro-expression detection

✅ **Machine Learning Detection**
- Ensemble of specialized detectors (face-swap, lip-sync, GAN)
- Temporal CNN/RNN analysis
- Saliency map generation
- Explainable AI outputs

✅ **Skin & Feature Analysis**
- Texture uniformity detection
- Age-appropriate wrinkle verification
- Pore structure analysis
- Skin tone variation

## Project Structure

```
Lesson26_DeepFake/
├── deepfake_detector/          # Main package
│   ├── __init__.py            # Package initialization
│   ├── main.py                # CLI entry point
│   ├── config.py              # Configuration management
│   ├── detector.py            # Main orchestrator
│   │
│   ├── analyzers/             # Detection modules
│   │   ├── __init__.py
│   │   ├── facial_analyzer.py      # Facial expression & features
│   │   ├── temporal_analyzer.py    # Motion & temporal consistency
│   │   ├── metadata_analyzer.py    # Video metadata inspection
│   │   ├── lighting_analyzer.py    # Lighting & shadows
│   │   ├── geometry_analyzer.py    # Geometry & physiology
│   │   └── ml_detector.py          # Machine learning models
│   │
│   └── utils/                 # Utilities
│       ├── __init__.py
│       ├── logger.py          # Ring buffer logging
│       ├── video_processor.py # Frame extraction & processing
│       └── report_generator.py # Result reporting
│
├── log/                       # Ring buffer logs (20 × 16MB)
├── models/                    # Pre-trained ML models
├── tests/                     # Unit and integration tests
├── requirements.txt           # Python dependencies
├── README.md                  # This file
├── PRD.md                     # Product requirements
├── Claude.md                  # AI assistant notes
├── planning.md                # Development plan
└── tasks.md                   # Implementation tasks
```

## Installation

### Prerequisites

- **WSL:** Windows Subsystem for Linux (Ubuntu 20.04+ recommended)
- **Python:** 3.9 or higher
- **System packages:**
  ```bash
  sudo apt update
  sudo apt install python3.9 python3-pip python3-venv
  sudo apt install ffmpeg libsm6 libxext6 libxrender-dev
  sudo apt install libdlib-dev cmake
  ```

### Setup Virtual Environment

```bash
# Navigate to project parent directory
cd ../../

# Create virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate

# Navigate back to project
cd Lesson26/Lesson26_DeepFake

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
```

### Download Pre-trained Models

```bash
# Models will be automatically downloaded on first run
# Or manually download to models/ directory:
# - face_swap_detector.pth
# - lip_sync_detector.pth
# - gan_detector.onnx
```

## Usage

### Basic Usage

```bash
# Activate virtual environment
source ../../venv/bin/activate

# Run detection on a video file
python -m deepfake_detector.main path/to/video.mp4

# With custom output path
python -m deepfake_detector.main input.mp4 --output report.json

# Verbose logging
python -m deepfake_detector.main input.mp4 --verbose
```

### Advanced Options

```bash
# Skip frames for faster processing (analyze every Nth frame)
python -m deepfake_detector.main input.mp4 --frame-skip 3

# Custom number of worker processes
python -m deepfake_detector.main input.mp4 --workers 8

# Disable specific analyzers
python -m deepfake_detector.main input.mp4 --disable-ml

# Set confidence threshold
python -m deepfake_detector.main input.mp4 --threshold 0.7
```

### Python API

```python
from pathlib import Path
from deepfake_detector.detector import DeepFakeDetector
from deepfake_detector.config import DetectorConfig

# Initialize detector
config = DetectorConfig(
    frame_skip=1,
    batch_size=16,
    num_workers=4
)
detector = DeepFakeDetector(config)

# Analyze video
video_path = Path("path/to/video.mp4")
result = detector.analyze(video_path)

# Access results
print(f"Verdict: {result.verdict}")  # "REAL" or "FAKE"
print(f"Confidence: {result.confidence:.2%}")
print(f"Scores by criterion: {result.scores}")
```

## Output Format

### JSON Report Structure

```json
{
  "video_path": "path/to/video.mp4",
  "verdict": "FAKE",
  "confidence": 0.87,
  "analysis_date": "2025-12-28T10:30:45.123Z",
  "processing_time_sec": 45.2,
  "scores": {
    "facial_consistency": 0.65,
    "temporal_consistency": 0.72,
    "metadata_consistency": 0.90,
    "lighting_consistency": 0.55,
    "eye_analysis": 0.70,
    "geometry_consistency": 0.80,
    "ml_detection": 0.92,
    "skin_analysis": 0.68
  },
  "anomalies": [
    {
      "timestamp": 12.5,
      "frame": 300,
      "type": "lighting_inconsistency",
      "severity": "high",
      "description": "Shadow direction mismatch with facial lighting"
    },
    {
      "timestamp": 23.1,
      "frame": 554,
      "type": "missing_blinks",
      "severity": "medium",
      "description": "No blinks detected for 8.2 seconds"
    }
  ],
  "metadata": {
    "duration_sec": 60.0,
    "resolution": "1920x1080",
    "fps": 24.0,
    "codec": "h264",
    "container": "mp4"
  }
}
```

## Configuration

### Configuration File

Create `config.yaml` in the project root:

```yaml
detector:
  frame_skip: 1        # Process every Nth frame
  batch_size: 16       # Frames per batch
  num_workers: 4       # Parallel workers
  
analyzers:
  facial:
    enabled: true
    weight: 1.0
    threshold: 0.5
  
  temporal:
    enabled: true
    weight: 1.2
    threshold: 0.6
  
  lighting:
    enabled: true
    weight: 1.1
    threshold: 0.5
  
  ml:
    enabled: true
    weight: 1.5
    threshold: 0.7
    use_gpu: true

logging:
  level: INFO
  console: true
  file: true
```

### Environment Variables

```bash
export DEEPFAKE_LOG_LEVEL=INFO
export DEEPFAKE_NUM_WORKERS=8
export DEEPFAKE_MODEL_DIR=./models
export DEEPFAKE_GPU_ENABLED=true
```

## Logging

The tool uses a **ring buffer logging system** with:
- **20 log files** × **16MB each** = **320MB total**
- Automatic rotation when files reach size limit
- Oldest file overwritten when buffer is full
- Logs stored in `log/` subdirectory

### Log Levels
- **DEBUG:** Frame-level details
- **INFO:** Pipeline stages, results summary (default)
- **WARNING:** Degraded performance, missing features
- **ERROR:** Analyzer failures, recoverable errors
- **CRITICAL:** Unrecoverable failures

### Log File Pattern
```
log/
├── deepfake.log        # Current log
├── deepfake.log.1      # Previous
├── deepfake.log.2
├── ...
└── deepfake.log.19     # Oldest
```

## Performance

### Benchmarks (1080p Video)

| System | FPS | Processing Speed |
|--------|-----|------------------|
| 4-core CPU | 5-7 FPS | ~0.5× real-time |
| 8-core CPU | 10-15 FPS | ~1.0× real-time |
| CPU + GPU | 20-30 FPS | ~2.0× real-time |

### Memory Usage
- Typical: 2-4GB
- Peak: 6-8GB (with all ML models loaded)
- Minimum: 8GB RAM recommended

### Optimization Tips
1. **Use frame skipping** for faster processing (--frame-skip 2)
2. **Enable GPU** if available for ML models
3. **Adjust batch size** based on available memory
4. **Disable unused analyzers** to save resources

## Testing

### Run Tests

```bash
# All tests
pytest tests/

# With coverage
pytest --cov=deepfake_detector tests/

# Specific test module
pytest tests/test_facial_analyzer.py

# Verbose output
pytest -v tests/
```

### Test Coverage Goals
- Unit tests: 80%+ coverage
- Integration tests: Full pipeline
- Performance benchmarks
- Edge case validation

## Troubleshooting

### Common Issues

**Issue:** `dlib` installation fails  
**Solution:**
```bash
sudo apt install libdlib-dev cmake build-essential
pip install dlib --no-cache-dir
```

**Issue:** Video file not supported  
**Solution:** Install additional codecs
```bash
sudo apt install ubuntu-restricted-extras
```

**Issue:** Out of memory errors  
**Solution:** Reduce batch size or enable frame skipping
```bash
python -m deepfake_detector.main input.mp4 --batch-size 8 --frame-skip 2
```

**Issue:** Models not found  
**Solution:** Ensure `models/` directory exists and download required models

## Development

### Code Style
- **PEP 8** compliant
- **Black** formatter
- **Type hints** for all functions
- **Docstrings** for all public APIs

### Contributing
1. Ensure all files remain under 150 lines
2. Add tests for new features
3. Update documentation
4. Run linting: `pylint deepfake_detector/`
5. Format code: `black deepfake_detector/`

### File Size Limit
Each Python file must be **under 150 lines**. Use:
- Modular design
- Helper utilities
- Clear separation of concerns

## License

The fake video was created from image by https://hailuoai.video/create/image-to-video. 

## Acknowledgments

- FaceForensics++ dataset and models
- Deepfake Detection Challenge (DFDC)
- Open source computer vision community

## References

1. [TechTarget: How to detect deepfakes manually and using AI](http://techtarget.com/searchsecurity/tip/How-to-detect-deepfakes-manually-and-using-AI)
2. [Resemble.ai: Deepfake Detection Methods & Techniques](https://www.resemble.ai/deepfake-detection-methods-techniques/)
3. [Quora: How does an expert detect fake videos from real videos](https://www.quora.com/How-does-an-expert-detect-fake-videos-from-real-videos)

## Contact

**Author:** Yair Levi  
**Project:** DeepFake Detection Tool  
**Repository:** [To be added]

---

**Note:** This tool is for educational and research purposes. Always verify results with manual inspection and expert analysis for critical applications.
