sumarry35
29/1/2026

Subject: Video compressing and processing.

In high resolution, each pixel show a lower view area. 
Low resolution: blurred image. Each pixel describe a higher area.

For far object, we get low light intensity, so we need more sensitive sensors,
or need to increase the exposure time.

The shutter control the light enter to the camera.
More light or less light as required, depends on exposure time and aperture size that can be tuned.

Mjpeg (Motion Jpeg):
This is video that each frame has jpeg compression.
This is actually a spatial compression.
We want spatial and temporal compression.
In video we have 30 FPS (frames per second).
One of the compression methods is to lower the FPS, depends on application and use, if it can suffer the reduce in video quality because of decreasing the FPS./
Resolution also influence the compression, but it is complex to calculate it from jpeg.
Mjpeg is obsolete because it does not consider the time domain. 

Block-based video codecs:
These are methods that use better compression and use also compression in the temporal domain.
They use I-Frame, P-Frame and B-Frame.
Standards that use it includes, H.264/AVC (Advanced Video Coding), H.265/HEVC (High Efficiency Video Coding), MPEG-2, MPEG-4 Part 2 and AV1.
All use GOP (Group of Pictures) that contains I-Frame, P-Frame and B-Frame as a group, while I-Frame uses as a reference.
I-Frame (Intra-coded Frame) is the first frame in and use as a reference.
It contains the full picture like a complete JPEG.
Playback usually starts at the I-Frame.
P-Frame (Predictive Frame) references earlier I or P frames, store only changes from previous frame.
if one frame is corrupted, errors will propagate forward.

How P-Frame is built:
P-Frame is build from the difference between the previous decoded frame (I-Frame or P-Frame) N frame and current raw frame that is N+1 frame.
1. divide into blocks:
The encoder divides Frame N+1 into blocks, typically 16x16 pixels (macroblocks) or smaller blocks (8x8, 4x4) in modern codecs (H.264 and HVEC).
2. Motion Estimation:
For each block in N+1 frame, the encoder searches for similar block in N frame.
The search area is usually limited (e.g. 32 pixels).
This is called block matching. 
As a result we get a "Motion Vector" that notify how many pixels the block moved in X and Y direction.
Big vector size means bigger displacement and hence higher speed.
3. Motion Compensation:
Take the matched block from frame N and shift it using the motion vector.
This becomes the prediction for the new block i N+1 frame, it is a prediction but not the real one.
4. Compute the residual (difference):
The residual is the difference between the prediction block (that moved from N frame) to the real actual block from N+1 frame.
Residual block = Actual block - Predicted block.
If prediction is perfect, residual is zero.
5. Transform & quantization:
These operations are done only on the residual block.
The residual is a block of signed pixel differences, generally these differences are small.
a. Transform:
   Convert from space (block of diff pixels values) to frequency by DCT method.
b. Quantization:
   Here the compression is done.
   In this step the coefficients of frequency are taken and decreased while higher frequency 
   coefficients are decreasing more than lower frequencies.
   This leads to Zero explosion, long runs of zeros.
   This helps the encoder to decode the data efficiently.
6. P-Frame stores the motion vectors and the quantized residual coefficients.

B- Frame (Bi-Directional Frame), References previous and next I/P frames.
It actually calculate the predicted block by averaging predict from previous frame and future frame.
The residual is the actual real block minus the predicted block.
It is the best compression efficiency but more complex to encode/decode.
B appears when latency is allowed.
Not ideal for real time streaming. 

GOP (Group of Pictures):
Group of the I-Frame with a few P-Frames and B-Frames is called GOP.
The receiver waits for the GOP to be in its buffer, rearrange the frames and present it.
We divides into GOPs, because in each GOP the differences are quite small.
GOP is generally about 100 frames.
This parameter can be changed.

If latency must be minimal, we can decrease the GOP.
Another option is to skip using the B frame, so we cannot wait to the next P.
Security camera works without B frames.

Temporal compression principle:
Motion Vector:
The picture is divided into macro blocks.
If we have moving object, it moves between macro blocks with different background that it is the noise.
It was explained above in the P-Frame.

Container:
MP4 or AVI video formats are containers.
Container is a file that contains a few of what is called channels.
Channel can contain a video, audio, text information, etc.
For example, these are channels:
H264 - compress video.
MP3 - compressed Audio.
STR - Subtitles Channel for subtitles during the video.
There are more options, can be an English audio channel plus Hebrew audio channel.

VLC is a player that can play many format types and can convert format types.
To convert to another coding scheme, in the menu choose: Media-->Open Network Stream...
Choose the "Capture Device" tab.
In the "Advanced Options" button you can change the the format parameters.
In the "Play" dropdown list, you can choose "convert" and then in the "Profile" 
dropdown list change to another standard.
View the video parameters:
Open any file by menu: Media-->Open file...
Stop the video.
At the menu choose: Tools-->Media Information.
A new window will be opened with parameters of stream 0, the video and channel 1, the audio (mp4 example).
In the other tabs of this window, there are statistics that is updating when the movie is playing.

In Image processing we work on raw data and not jpeg, so the model need to get raw data.
Sometimes we will get a video and we are required to analyze it.
We will have a video, divide it to frames, decode them and store the frames in one folder.
Then you can give the folder name to the LLM and the model can take the frame you want in the video.

Homework:
The VLC player use an compress/decompress engine.
This is called FFMPEG. It is a SW, includes all formats.
You can run FFMPEG.exe (windows version) with parameters.
With the correct parameters, you can take a video and divide it into frames.
You can convert the frames to raw data.
Take a very short video one minute or less that contains a moving object, divide to frames.
The video should be long enough to contain a few GOPs.
1. Find all movie characters: GOP, I-Frame length, resolution, works with B-Frames or not, statistics and more.
2. Isolate the frames from the video and store them in ./decoded_frames/ folder. 
   Ask the FFMPEG to draw the macro blocks on the frame  and label the moving vectors of each frame.
   Look at the frame and check if you see a moving flow.
   The vector length meaning is the speed of movement.
3. Draw an black object, size 20x10 pixels moving in the frames, from top left to bottom right, 
   so it will move in the video.






